{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "#### Create a classifier to tell whether a SMS message is spam or ham\n",
    "\n",
    "ML Framework: Scikit-learn\n",
    "Algorithm: Decision Tree\n",
    "\n",
    "##### Why this frame-work and model is choose?\n",
    "The KISS principle in machine learning - Simple solutions are to be preferred, while unnecessary complexity should be avoided. In machine learning its good to start with simple models, if required/neccessary we can work upwards towards complicated ones.\n",
    "\n",
    "Models used:\n",
    "+ Non-Linear alorithm: Decision Tree\n",
    "+ Naive algorithm: Naive Bayes\n",
    "+ Ensemble algorithm: Balanced Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import platform\n",
    "import chardet\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup\n",
    "Creating dataset for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize system dir path\n",
    "\n",
    "system_env = platform.system().lower()\n",
    "if system_env == 'linux':\n",
    "    BASE_DIR = '/tmp/nlp_spam_ham'\n",
    "else:\n",
    "    BASE_DIR = 'C:\\nlp_spam_ham'\n",
    "\n",
    "os.makedirs(BASE_DIR, mode=0o777, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-24 21:30:19--  https://rizcodes-aiml.s3.us-east-2.amazonaws.com/public/spam.csv\n",
      "Resolving rizcodes-aiml.s3.us-east-2.amazonaws.com (rizcodes-aiml.s3.us-east-2.amazonaws.com)... 52.219.100.232\n",
      "Connecting to rizcodes-aiml.s3.us-east-2.amazonaws.com (rizcodes-aiml.s3.us-east-2.amazonaws.com)|52.219.100.232|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 503663 (492K) [text/csv]\n",
      "Saving to: ‘spam.csv’\n",
      "\n",
      "spam.csv            100%[===================>] 491.86K   527KB/s    in 0.9s    \n",
      "\n",
      "2021-01-24 21:30:21 (527 KB/s) - ‘spam.csv’ saved [503663/503663]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['spam.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change directory and download the dataset\n",
    "\n",
    "os.chdir(BASE_DIR)\n",
    "!wget https://rizcodes-aiml.s3.us-east-2.amazonaws.com/public/spam.csv\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'Windows-1252', 'confidence': 0.7270322499829184, 'language': ''}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset as DataFrame\n",
    "\n",
    "DATA_CSV = os.path.join(BASE_DIR, 'spam.csv')\n",
    "\n",
    "# Detect Character encoding\n",
    "with open(DATA_CSV, 'rb') as f:\n",
    "    char_encoding = chardet.detect(f.read(100000))\n",
    "print (char_encoding)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.read_csv(DATA_CSV, encoding=char_encoding.get('encoding'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               data\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the Data\n",
    "\n",
    "df.dropna(axis='columns', inplace=True)\n",
    "df.columns = [\"label\", \"data\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5572 non-null   int64 \n",
      " 1   data    5572 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Encode the labels\n",
    "\n",
    "df.replace({'label': {'ham': 0, 'spam': 1}}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of ham samples: 4825\n",
      "Num of spam samples: 747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'label'}>]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_ham = df[df.label == 0].data.count()\n",
    "num_spam = df[df.label == 1].data.count()\n",
    "print (f'Num of ham samples: {num_ham}\\nNum of spam samples: {num_spam}')\n",
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing\n",
    "Cleaning and text processing\n",
    "+ Eliminate unnecessary characters\n",
    "+ Tokenize\n",
    "+ Normalization - Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download nltk libraries\n",
    "\n",
    "nltk.download()\n",
    "from nltk.corpus import brown\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the message data\n",
    "\n",
    "# Get messages\n",
    "messages = df.data.to_list()\n",
    "# Tokenizer and remove all special charaters\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "# Get stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def normalize_text(msg):\n",
    "    norm_msg = []\n",
    "    sentence = tokenizer.tokenize(msg)\n",
    "    for word in sentence:\n",
    "        if (word in stop_words) or (word.isspace()) or (word==''):\n",
    "            continue\n",
    "        s_word = stemmer.stem(word)\n",
    "        norm_msg.append(s_word)\n",
    "    return \" \".join(norm_msg)\n",
    "\n",
    "final_data = [normalize_text(msg) for msg in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entri 2 wkli comp win FA cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say earli hor U c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah I think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           messages\n",
       "0      0  Go jurong point crazi avail bugi n great world...\n",
       "1      0                              Ok lar joke wif u oni\n",
       "2      1  free entri 2 wkli comp win FA cup final tkt 21...\n",
       "3      0                U dun say earli hor U c alreadi say\n",
       "4      0             nah I think goe usf live around though"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the normalized data into DataFrame\n",
    "\n",
    "df['messages'] = final_data\n",
    "df.drop(columns=['data'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Machine learning models\n",
    "+ Decision tree\n",
    "+ Naive Bayes\n",
    "+ Balanced bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4736,), (836,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting Train and Test data\n",
    "\n",
    "X = df.messages\n",
    "y = df.label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4736, 6728), (836, 6728))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the features\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "train_vectors.shape, test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 97.36842105263158\n",
      "\n",
      "Precision-Recall-F1_Score:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       728\n",
      "           1       0.91      0.88      0.90       108\n",
      "\n",
      "    accuracy                           0.97       836\n",
      "   macro avg       0.95      0.93      0.94       836\n",
      "weighted avg       0.97      0.97      0.97       836\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[719   9]\n",
      " [ 13  95]]\n"
     ]
    }
   ],
   "source": [
    "# ML non-linear algorithm - DecisionTree\n",
    "\n",
    "# Train data\n",
    "model_dt = DecisionTreeClassifier()\n",
    "model_dt.fit(train_vectors, y_train)\n",
    "\n",
    "# Predict test data\n",
    "y_pred_dt = model_dt.predict(test_vectors)\n",
    "\n",
    "# Model metrics\n",
    "model_accuracy_score_dt = model_dt.score(test_vectors, y_test)\n",
    "print (f'Decision Tree Accuracy: {model_accuracy_score_dt * 100}')\n",
    "print (f'\\nPrecision-Recall-F1_Score:\\n{classification_report(y_test,y_pred_dt)}')\n",
    "print (f'\\nConfusion matrix:\\n {confusion_matrix(y_test,y_pred_dt)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 97.24880382775119\n",
      "\n",
      "Precision-Recall-F1_Score:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       728\n",
      "           1       1.00      0.79      0.88       108\n",
      "\n",
      "    accuracy                           0.97       836\n",
      "   macro avg       0.98      0.89      0.93       836\n",
      "weighted avg       0.97      0.97      0.97       836\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[728   0]\n",
      " [ 23  85]]\n"
     ]
    }
   ],
   "source": [
    "# ML naive algorithm - Naive Bayes\n",
    "\n",
    "# Train data\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(train_vectors, y_train)\n",
    "\n",
    "# Predict test data\n",
    "y_pred_nb = model_nb.predict(test_vectors)\n",
    "\n",
    "# Model metrics\n",
    "model_accuracy_score_nb = model_nb.score(test_vectors, y_test)\n",
    "print (f'Naive Bayes Accuracy: {model_accuracy_score_nb * 100}')\n",
    "print (f'\\nPrecision-Recall-F1_Score:\\n{classification_report(y_test,y_pred_nb)}')\n",
    "print (f'\\nConfusion matrix:\\n {confusion_matrix(y_test,y_pred_nb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancedBaggingClassifier Accuracy: 94.97607655502392\n",
      "\n",
      "Precision-Recall-F1_Score:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       728\n",
      "           1       0.76      0.89      0.82       108\n",
      "\n",
      "    accuracy                           0.95       836\n",
      "   macro avg       0.87      0.92      0.90       836\n",
      "weighted avg       0.95      0.95      0.95       836\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      " [[698  30]\n",
      " [ 12  96]]\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced dataset handling - BalancedBagging using DT (Ensemble)\n",
    "\n",
    "model_bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                      sampling_strategy='auto',\n",
    "                                      replacement=False,\n",
    "                                      random_state=0)\n",
    "model_bbc.fit(train_vectors, y_train)\n",
    "y_pred_bbc = model_bbc.predict(test_vectors)\n",
    "\n",
    "# Model metrics\n",
    "model_accuracy_score_bbc = model_bbc.score(test_vectors, y_test)\n",
    "print (f'BalancedBaggingClassifier Accuracy: {model_accuracy_score_bbc * 100}')\n",
    "print (f'\\nPrecision-Recall-F1_Score:\\n{classification_report(y_test,y_pred_bbc)}')\n",
    "print (f'\\nConfusion matrix:\\n {confusion_matrix(y_test,y_pred_bbc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "+ Though all models have good accuray, after observing the f1-score\n",
    "+ Decision-Tree classifier has better metrics compared to other two\n",
    "+ Naive-bayes: Sufferred recall due to its more false-negatives\n",
    "+ BalanceBaggingClassifier: Suffered precision due to its more false-positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the data with the trained model\n",
    "model = model_dt\n",
    "\n",
    "def decode_label(num):\n",
    "    \"\"\"Returns the message label value as string\n",
    "    \"\"\"\n",
    "    if num == 1:\n",
    "        return 'spam'\n",
    "    return 'ham'\n",
    "\n",
    "def predict_message(raw_data):\n",
    "    \"\"\"Classifies the incoming message as either 'ham' or 'spam'\n",
    "    \"\"\"\n",
    "    raw_input = {'data': [raw_data]}\n",
    "    df_input = pd.DataFrame(raw_input)\n",
    "    data_input = df_input.data\n",
    "    feature_vector = vectorizer.transform(data_input)\n",
    "    predicted_label = model.predict(feature_vector)\n",
    "    \n",
    "    return decode_label(int(predicted_label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Message: you won guarante å 1000 cash å 2000 prize To claim yr prize call custom servic repres\n",
      "Prediction: spam\n",
      "Expected: spam\n"
     ]
    }
   ],
   "source": [
    "# Test a random message\n",
    "i = np.random.randint(500)\n",
    "input_data = X_test.iloc[i]\n",
    "y_hat = predict_message(input_data)\n",
    "print(f'Test Message: {input_data}\\nPrediction: {y_hat}\\nExpected: {decode_label(y_test.iloc[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and vectorizer\n",
    "\n",
    "model_file_name = 'dt_model.pkl'\n",
    "tfidf_file_name = 'tfidf.pkl'\n",
    "pickle.dump(model, open(model_file_name, 'wb'))\n",
    "pickle.dump(vectorizer, open(tfidf_file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from file\n",
    "\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "aiml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
